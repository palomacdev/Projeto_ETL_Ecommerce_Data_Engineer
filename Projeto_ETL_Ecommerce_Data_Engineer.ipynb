{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMom3BYKXCpUBK8q85eCJTf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/palomadevfullstack/portfolio/blob/main/Projeto_ETL_Ecommerce_Data_Engineer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k7Qsurp_Jar",
        "outputId": "020ebe3d-56a6-4a0c-fd67-addf2d745f3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- DataFrames Extraídos ---\n",
            "\n",
            "DF Vendas:\n",
            "   transaction_id product_sku customer_id        date  quantity  revenue\n",
            "0             101      SKU001        C100  2025-01-01         1     50.0\n",
            "1             102      SKU002        C101  2025-01-01         2    150.0\n",
            "2             103      SKU001        C100  2025-01-02         1     50.0\n",
            "3             104      sku003        C102  2025-01-02         3     30.0\n",
            "4             105      SKU002        C101  2025-01-03         1     75.0\n",
            "\n",
            "DF Produtos:\n",
            "      SKU            name     category   cost\n",
            "0  SKU001   Laptop Básico  Electronics   30.0\n",
            "1  SKU002     Monitor 27\"  Electronics   50.0\n",
            "2  SKU003     Mouse Gamer  Peripherals    5.0\n",
            "3  SKU004  Câmera Full HD          NaN  100.0\n",
            "4  SKU005         Teclado  Peripherals   15.0\n"
          ]
        }
      ],
      "source": [
        "# Importação e Extração de Dados Fictícios\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Extração: vendas\n",
        "data_vendas = {\n",
        "    'transaction_id': [101, 102, 103, 104, 105, 106],\n",
        "    'product_sku': ['SKU001', 'SKU002', 'SKU001', 'sku003', 'SKU002', 'SKU004'],\n",
        "    'customer_id': ['C100', 'C101', 'C100', 'C102', 'C101', 'C103'],\n",
        "    'date': ['2025-01-01', '2025-01-01', '2025-01-02', '2025-01-02', '2025-01-03', '2025-01-03'],\n",
        "    'quantity': [1, 2, 1, 3, 1, 1],\n",
        "    'revenue': [50.00, 150.00, 50.00, 30.00, 75.00, 200.00]\n",
        "}\n",
        "df_vendas = pd.DataFrame(data_vendas)\n",
        "\n",
        "# 2. Extração: produtos\n",
        "data_produtos = {\n",
        "    'SKU': ['SKU001', 'SKU002', 'SKU003', 'SKU004', 'SKU005'],\n",
        "    'name': ['Laptop Básico', 'Monitor 27\"', 'Mouse Gamer', 'Câmera Full HD', 'Teclado'],\n",
        "    'category': ['Electronics', 'Electronics', 'Peripherals', np.nan, 'Peripherals'],\n",
        "    'cost': [30.00, 50.00, 5.00, 100.00, 15.00]\n",
        "}\n",
        "df_produtos = pd.DataFrame(data_produtos)\n",
        "\n",
        "# 3. Extração: clientes\n",
        "data_clientes = {\n",
        "    'ID': ['C100', 'C101', 'C102', 'C103', 'C104'],\n",
        "    'name': ['Ana Silva', 'Bruno Costa', 'Carlos Dantas', 'Daniela Reis', 'Eduarda Souza'],\n",
        "    'city': ['São Paulo', 'Rio de Janeiro', 'são paulo', 'Porto Alegre', 'Curitiba']\n",
        "}\n",
        "df_clientes = pd.DataFrame(data_clientes)\n",
        "\n",
        "print(\"--- DataFrames Extraídos ---\")\n",
        "print(\"\\nDF Vendas:\")\n",
        "print(df_vendas.head())\n",
        "print(\"\\nDF Produtos:\")\n",
        "print(df_produtos.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformação de Dados\n",
        "\n",
        "# 1. Padronização produto\n",
        "df_vendas['product_sku'] = df_vendas['product_sku'].str.upper()\n",
        "df_produtos.rename(columns={'SKU': 'product_sku'}, inplace=True) # Renomeia para facilitar o JOIN\n",
        "\n",
        "# 2. Padronização clientes\n",
        "df_clientes.rename(columns={'ID': 'customer_id'}, inplace=True)\n",
        "\n",
        "# Limpeza de Dados nulos\n",
        "df_produtos['category'].fillna('Desconhecida', inplace=True)\n",
        "\n",
        "# Padronização cidade dos clientes\n",
        "df_clientes['city'] = df_clientes['city'].str.title()\n",
        "\n",
        "print(\"--- DataFrames Transformados (Limpeza) ---\")\n",
        "print(\"\\nDF Vendas (Chave Padronizada):\")\n",
        "print(df_vendas)\n",
        "print(\"\\nDF Clientes (Cidades Padronizadas):\")\n",
        "print(df_clientes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rWT_ews_-lK",
        "outputId": "9fe1660d-f884-4098-a4d7-1a650d03cadb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- DataFrames Transformados (Limpeza) ---\n",
            "\n",
            "DF Vendas (Chave Padronizada):\n",
            "   transaction_id product_sku customer_id        date  quantity  revenue\n",
            "0             101      SKU001        C100  2025-01-01         1     50.0\n",
            "1             102      SKU002        C101  2025-01-01         2    150.0\n",
            "2             103      SKU001        C100  2025-01-02         1     50.0\n",
            "3             104      SKU003        C102  2025-01-02         3     30.0\n",
            "4             105      SKU002        C101  2025-01-03         1     75.0\n",
            "5             106      SKU004        C103  2025-01-03         1    200.0\n",
            "\n",
            "DF Clientes (Cidades Padronizadas):\n",
            "  customer_id           name            city\n",
            "0        C100      Ana Silva       São Paulo\n",
            "1        C101    Bruno Costa  Rio De Janeiro\n",
            "2        C102  Carlos Dantas       São Paulo\n",
            "3        C103   Daniela Reis    Porto Alegre\n",
            "4        C104  Eduarda Souza        Curitiba\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1924878229.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_produtos['category'].fillna('Desconhecida', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tranformação / Integração\n",
        "#Juntar produtos com Vendas\n",
        "df_stage = pd.merge(\n",
        "    df_vendas,\n",
        "    df_produtos,\n",
        "    on='product_sku',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Juntar o resultado com Clientes\n",
        "df_datamart = pd.merge(\n",
        "    df_stage,\n",
        "    df_clientes,\n",
        "    on='customer_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "df_datamart['total_cost'] = df_datamart['cost'] * df_datamart['quantity']\n",
        "df_datamart['profit'] = df_datamart['revenue'] - df_datamart['total_cost']\n",
        "\n",
        "print(\"--- Data Mart Final (Primeiras 5 linhas) ---\")\n",
        "print(df_datamart.head())\n",
        "\n",
        "# Inspecção final\n",
        "print(\"\\nDF Info Final:\")\n",
        "print(df_datamart.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBU_sHuVAhdU",
        "outputId": "e4787c1c-c482-4071-b576-40358c291b74"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data Mart Final (Primeiras 5 linhas) ---\n",
            "   transaction_id product_sku customer_id        date  quantity  revenue  \\\n",
            "0             101      SKU001        C100  2025-01-01         1     50.0   \n",
            "1             102      SKU002        C101  2025-01-01         2    150.0   \n",
            "2             103      SKU001        C100  2025-01-02         1     50.0   \n",
            "3             104      SKU003        C102  2025-01-02         3     30.0   \n",
            "4             105      SKU002        C101  2025-01-03         1     75.0   \n",
            "\n",
            "          name_x     category  cost         name_y            city  \\\n",
            "0  Laptop Básico  Electronics  30.0      Ana Silva       São Paulo   \n",
            "1    Monitor 27\"  Electronics  50.0    Bruno Costa  Rio De Janeiro   \n",
            "2  Laptop Básico  Electronics  30.0      Ana Silva       São Paulo   \n",
            "3    Mouse Gamer  Peripherals   5.0  Carlos Dantas       São Paulo   \n",
            "4    Monitor 27\"  Electronics  50.0    Bruno Costa  Rio De Janeiro   \n",
            "\n",
            "   total_cost  profit  \n",
            "0        30.0    20.0  \n",
            "1       100.0    50.0  \n",
            "2        30.0    20.0  \n",
            "3        15.0    15.0  \n",
            "4        50.0    25.0  \n",
            "\n",
            "DF Info Final:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6 entries, 0 to 5\n",
            "Data columns (total 13 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   transaction_id  6 non-null      int64  \n",
            " 1   product_sku     6 non-null      object \n",
            " 2   customer_id     6 non-null      object \n",
            " 3   date            6 non-null      object \n",
            " 4   quantity        6 non-null      int64  \n",
            " 5   revenue         6 non-null      float64\n",
            " 6   name_x          6 non-null      object \n",
            " 7   category        6 non-null      object \n",
            " 8   cost            6 non-null      float64\n",
            " 9   name_y          6 non-null      object \n",
            " 10  city            6 non-null      object \n",
            " 11  total_cost      6 non-null      float64\n",
            " 12  profit          6 non-null      float64\n",
            "dtypes: float64(4), int64(2), object(7)\n",
            "memory usage: 756.0+ bytes\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga e Simulação\n",
        "\n",
        "colunas_finais = [\n",
        "    'date', 'transaction_id', 'customer_id', 'product_sku', 'name_x', 'category',\n",
        "    'quantity', 'revenue', 'cost', 'total_cost', 'profit', 'city'\n",
        "]\n",
        "df_final_load = df_datamart[colunas_finais].copy()\n",
        "\n",
        "# Salvamento (Simulação do 'L' de Load)\n",
        "df_final_load.to_parquet('ecommerce_data_mart.parquet', index=False)\n",
        "\n",
        "print(\"\\n[SUCESSO] Pipeline ETL concluído!\")\n",
        "print(\"O Data Mart foi salvo como 'ecommerce_data_mart.parquet'.\")\n",
        "print(\"Pronto para ser consumido por analistas ou modelos de ML.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2zL015JBA71",
        "outputId": "9b56d74f-5f6f-4edd-93fd-9eedcecf011b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUCESSO] Pipeline ETL concluído!\n",
            "O Data Mart foi salvo como 'ecommerce_data_mart.parquet'.\n",
            "Pronto para ser consumido por analistas ou modelos de ML.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Conclusão de Engenharia de Dados: Pipeline ETL\n",
        "\n",
        "## Demonstração de Habilidades\n",
        "Este projeto demonstrou as habilidades essenciais de Engenharia de Dados:\n",
        "* **Extração (E):** Coleta de dados de múltiplas fontes (simuladas em DataFrames).\n",
        "* **Transformação (T):** Tratamento de qualidade (padronização de `SKU`, `city`), tratamento de nulos (`category`) e **integração** (`pd.merge`).\n",
        "* **Modelagem/Feature Engineering:** Criação de novas colunas de negócio (`total_cost`, `profit`).\n",
        "* **Carga (L):** Persistência do resultado em um formato otimizado (`.parquet`), pronto para consumo.\n",
        "\n",
        "## Esquema de Dados (Data Mart)\n",
        "\n",
        "| Coluna | Tipo | Origem | Finalidade |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| `date` | datetime | Vendas | Chave Temporal para Análise de Séries |\n",
        "| `product_sku` | string | Vendas/Produtos | Chave de Ligação |\n",
        "| `category` | string | Produtos | Variável de Agrupamento |\n",
        "| `revenue` | float | Vendas | Variável de Negócio |\n",
        "| `profit` | float | Transf. | KPI Principal (Lucro da Transação) |\n",
        "| `city` | string | Clientes | Variável Geográfica |\n",
        "\n",
        "Este Data Mart unificado está em um formato que reduz o tempo de consulta para Analistas de Dados, cumprindo a função principal de um Engenheiro de Dados."
      ],
      "metadata": {
        "id": "yIA1UU9yBSNZ"
      }
    }
  ]
}